{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimCLR attempt using Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LD_LIBRARY_PATH\"]='/opt/conda/lib'\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/opt/conda/pkgs/cuda-toolkit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(x_train[0], cmap=\"gray\")\n",
    "plt.show()\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_train[0]\n",
    "a.shape\n",
    "plt.imshow(a)\n",
    "plt.show()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize(image):\n",
    "    crop_percent = np.random.uniform(0.4, 1)\n",
    "\n",
    "    if crop_percent == 1:\n",
    "        return image\n",
    "        \n",
    "    # Get width and height from the image shape\n",
    "    width = image.shape[0]\n",
    "    height = image.shape[1]\n",
    "\n",
    "    # Create new dimensions for the image\n",
    "    crop_width = int(width * crop_percent)\n",
    "    crop_height = int(height * crop_percent)\n",
    "    print(crop_width, crop_height, '\\n')\n",
    "\n",
    "    cropped = tf.image.random_crop(tf.expand_dims(image, -1), (crop_width, crop_height, 1))\n",
    "    cropped = tf.image.resize(cropped, (image.shape[0], image.shape[1]))\n",
    "    return cropped\n",
    "\n",
    "b = crop_and_resize(a)\n",
    "b.shape\n",
    "plt.imshow(b)\n",
    "plt.show()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x, y, batch_size=32, num_batches=100, rng: np.random.Generator = np.random.default_rng(), min_crop = .5, max_crop = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Group by labels\n",
    "        groups = [[] for _ in range(len(np.unique(y)))]\n",
    "        for x_i, y_i in zip(x, y):\n",
    "            groups[y_i].append(x_i)\n",
    "        groups = list(map(np.array, groups))\n",
    "\n",
    "        self.groups = groups\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = num_batches\n",
    "        self.rng = rng\n",
    "\n",
    "        self.min_crop = min_crop\n",
    "        self.max_crop = max_crop\n",
    "\n",
    "        self.shuffle()\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.labels = self.rng.integers(len(self.groups), size=(self.num_batches, self.batch_size))   # Which labels to draw\n",
    "        self.variants = self.rng.uniform(size=(self.num_batches, 2, self.batch_size)) # Which variant of the label\n",
    "\n",
    "    # Function to randomly crop the image\n",
    "    def crop_and_resize(self, image):\n",
    "        crop_percent = np.random.uniform(self.min_crop, self.max_crop)\n",
    "    \n",
    "        if crop_percent == 1:\n",
    "            return image\n",
    "            \n",
    "        # Get width and height from the image shape\n",
    "        width = image.shape[0]\n",
    "        height = image.shape[1]\n",
    "    \n",
    "        # Create new dimensions for the image\n",
    "        crop_width = int(width * crop_percent)\n",
    "        crop_height = int(height * crop_percent)\n",
    "    \n",
    "        cropped = tf.image.random_crop(image, (crop_width, crop_height, 1))\n",
    "        # cropped = tf.squeeze(tf.image.resize(cropped, image.shape))\n",
    "        \n",
    "        return cropped\n",
    "\n",
    "\n",
    "    def __getitem__(self, batch_index):\n",
    "        batch = ([], [])\n",
    "        for label, variant_a, variant_b in zip(self.labels[batch_index], *self.variants[batch_index]):\n",
    "            group = self.groups[label]\n",
    "            variant_a_index = int(len(group)*variant_a)\n",
    "            # Instead of using two different batches, use the same with different augmentations:\n",
    "            image_a = self.crop_and_resize(group[variant_a_index])\n",
    "            image_b = self.crop_and_resize(group[variant_a_index])\n",
    "\n",
    "            batch[0].append(image_a)\n",
    "            batch[1].append(image_b)\n",
    "            \n",
    "        return tuple(np.array(batch)) # batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generator Testing/Debugging\n",
    "# [batch, x/y, set, image]\n",
    "data = DataGenerator(x_train, y_train, rng=np.random.default_rng(0), min_crop = 0.4, max_crop = 1)\n",
    "batch_index = 0\n",
    "index = 0\n",
    "plt.subplot(121)\n",
    "plt.imshow(data[batch_index][0][index])\n",
    "plt.subplot(122)\n",
    "plt.imshow(data[batch_index][1][index])\n",
    "plt.show()\n",
    "data[batch_index][0][index].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize the -input- data between 0.0-1.0 (real)\n",
    "## instead of the default 0-255 (integer)\n",
    "x_train = np.expand_dims(x_train,-1)\n",
    "x_val = np.expand_dims(x_val,-1)\n",
    "\n",
    "display(x_train.shape)\n",
    "display(y_train.shape)\n",
    "display(x_val.shape)\n",
    "display(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                   key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [keras.layers.Dense(ff_dim, activation=\"gelu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        y = x\n",
    "        y = self.layernorm1(y, training=training)\n",
    "        y, scores = self.att(y, y, return_attention_scores=True, training=training)\n",
    "        y = self.dropout1(y, training=training)\n",
    "        x += y\n",
    "        y = x\n",
    "        y = self.layernorm2(y, training=training)\n",
    "        y = self.ffn(y, training=training)\n",
    "        y = self.dropout2(y, training=training)\n",
    "        return (x + y, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-2] # x already embedded\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "kernel = 4\n",
    "num_heads = 6\n",
    "ff_dim = 512\n",
    "stack = 5\n",
    "\n",
    "# Note the input size (there is only one channel - intensity)\n",
    "# these images... if you are using color images, your would\n",
    "# need to set the last dimension of the input_shape to -3-\n",
    "# above and this would carry over into this cell...\n",
    "y = x = keras.layers.Input(shape=x_train.shape[1:])\n",
    "# This layer will just be passed a constant integer for\n",
    "# embedding (class token - see the ViT paper)\n",
    "# input_class = keras.layers.Input(shape=(1,))\n",
    "\n",
    "# Patches\n",
    "y = keras.layers.Conv2D(embed_dim,\n",
    "                        kernel_size=(kernel,kernel),\n",
    "                        strides=(kernel,kernel))(y)\n",
    "# Hybrid CNN\n",
    "# y = keras.layers.Conv2D(embed_dim*2,\n",
    "#                         kernel_size=(5, 5),\n",
    "#                         strides=2,\n",
    "#                         activation='gelu')(y)\n",
    "# y = keras.layers.Conv2D(embed_dim,\n",
    "#                         kernel_size=(5, 5),\n",
    "#                         strides=2,\n",
    "#                         activation='gelu')(y)\n",
    "\n",
    "# Flatten 2D arrangement to 1D arrangement of tokens\n",
    "y = keras.layers.Reshape((-1,embed_dim))(y)\n",
    "y = PositionEmbedding(y.shape[-2],embed_dim)(y)\n",
    "\n",
    "# Create class token\n",
    "c = keras.layers.Lambda(lambda x: tf.tile(tf.constant([[0]]),(tf.shape(x)[0],1)))(y)\n",
    "c = keras.layers.Embedding(input_dim=1,output_dim=embed_dim)(c)\n",
    "\n",
    "# Prepend class token\n",
    "y = keras.layers.Concatenate(axis=1)([c,y])\n",
    "\n",
    "for _ in range(stack):\n",
    "    y = TransformerBlock(embed_dim, num_heads, ff_dim)(y)[0]\n",
    "# Lambda layer is like the ViT the paper...\n",
    "# y = keras.layers.Lambda(lambda x: x[:,0,:])(y)\n",
    "# Use the following -instead- of Lambda is common in other\n",
    "# models I have seen... probably not important though\n",
    "y = keras.layers.GlobalAveragePooling1D()(y)\n",
    "y = keras.layers.Dropout(0.1)(y)\n",
    "y = keras.layers.Dense(embed_dim,activation='gelu')(y)\n",
    "#    y = keras.layers.Dropout(0.5)(y)\n",
    "y = keras.layers.Dense(10)(y)\n",
    "\n",
    "model = keras.Model(x,y)\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=keras.metrics.SparseCategoricalAccuracy())\n",
    "model.summary()\n",
    "keras.utils.plot_model(model,show_shapes=True,expand_nested=True)\n",
    "\n",
    "masked_encoder = model\n",
    "unmasked_encoder = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This metric only *correlates* with accuracy\n",
    "\n",
    "This is an approximate accuracy which doesn't really track the model's actual performance, and is just used here as a metric to show progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
    "def ContrastiveAccuracy(y_true, y_pred):\n",
    "    # return accuracy(y_true[tf.argmax(y_pred,-1)],\n",
    "    #                 y_pred)\n",
    "    acc_masked = accuracy(y_true, y_pred)\n",
    "    acc_unmasked = accuracy(y_true, tf.transpose(y_pred))\n",
    "    acc = (acc_masked + acc_unmasked) / 2.0\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrastiveModel(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        masked_encoder: tf.keras.Model,\n",
    "        unmasked_encoder: tf.keras.Model,\n",
    "        embed_dim: int = 512,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.masked_encoder = masked_encoder\n",
    "        self.unmasked_encoder = unmasked_encoder\n",
    "\n",
    "#         self.masked_encoder.trainable = False\n",
    "#         self.unmasked_encoder.trainable = False\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.W_masked = tf.keras.layers.Dense(\n",
    "            self.embed_dim,\n",
    "            # input_shape=self.masked_encoder.output_shape[-1],\n",
    "            use_bias=False)\n",
    "        self.W_unmasked = tf.keras.layers.Dense(\n",
    "            self.embed_dim,\n",
    "            # input_shape=self.unmasked_encoder.output_shape[-1],\n",
    "            use_bias=False)\n",
    "        self.t = self.add_weight(\n",
    "            name=\"Temperature\",\n",
    "            shape=None,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        return super().compile(\n",
    "            *args,\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            **kwargs)\n",
    "\n",
    "    def test_step(self, data):\n",
    "        n = tf.shape(data[0])[0]\n",
    "        y_true = tf.range(n)\n",
    "        y_pred = self(data, training=False)\n",
    "        loss_masked = self.compiled_loss(y_true, y_pred)\n",
    "        loss_unmasked = self.compiled_loss(y_true, tf.transpose(y_pred))\n",
    "        loss = (loss_masked + loss_unmasked) / 2.0\n",
    "        self.compiled_metrics.update_state(y_true, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        n = tf.shape(data[0])[0]\n",
    "        y_true = tf.range(n)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(data, training=True)\n",
    "            loss_masked = self.compiled_loss(y_true, y_pred)\n",
    "            loss_unmasked = self.compiled_loss(y_true, tf.transpose(y_pred))\n",
    "            loss = (loss_masked + loss_unmasked) / 2.0\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(y_true, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Get the images from input\n",
    "        masked_images, unmasked_images = inputs[0], inputs[1]\n",
    "\n",
    "        # Embed them using the encoders\n",
    "        masked_features = self.masked_encoder(masked_images)\n",
    "        unmasked_features = self.unmasked_encoder(unmasked_images)\n",
    "\n",
    "        # Joint multimodal embedding\n",
    "        masked_embeddings = self.W_masked(masked_features)\n",
    "        unmasked_embeddings = self.W_unmasked(unmasked_features)\n",
    "\n",
    "        # Normalize\n",
    "        masked_embeddings = masked_embeddings / tf.norm(masked_embeddings)\n",
    "        unmasked_embeddings = unmasked_embeddings / tf.norm(unmasked_embeddings)\n",
    "\n",
    "        logits = tf.tensordot(masked_embeddings, tf.transpose(unmasked_embeddings), axes=1) * tf.exp(self.t)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = ContrastiveModel(masked_encoder, unmasked_encoder)\n",
    "cm.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\n",
    "        ContrastiveAccuracy\n",
    "    ],\n",
    "    run_eagerly=False # Set to true to debug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][1][:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm((data[0][0][:4],data[0][1][:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = DataGenerator(x_train, y_train, batch_size=32, rng=np.random.default_rng(0), min_crop = 0.4, max_crop = 1)\n",
    "# No cropping\n",
    "validation_data = DataGenerator(x_val, y_val, batch_size=32, rng=np.random.default_rng(0), min_crop = 1, max_crop = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(training_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm(validation_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ContrastiveAccuracy(np.arange(validation_data[0][0].shape[0]),cm(validation_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", mode = 'min', patience = 15)\n",
    "history = cm.fit(training_data,\n",
    "                 epochs=300,\n",
    "                 verbose=1,\n",
    "                 validation_data=validation_data,\n",
    "                 callbacks=[callback]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_history.txt\", 'w') as file:\n",
    "    file.write(f\"Epochs: {len(history.history['loss'])}\\n\")\n",
    "    file.write(f\"Loss: {history.history['loss'][-1]}\\n\")\n",
    "    file.write(f\"Validation Loss: {history.history['val_loss'][-1]}\\n\")\n",
    "    file.write(f\"Contrastive Accuracy: {history.history['ContrastiveAccuracy'][-1] * 100}%\\n\")\n",
    "    file.write(f\"Validation Contrastive Accuracy: {history.history['val_ContrastiveAccuracy'][-1] * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.save_weights(\"Weights/ViT-11-18-23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot History in one image\n",
    "plt.figure(1)\n",
    "\n",
    "# Loss history\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['loss'],label='Training')\n",
    "plt.plot(history.history['val_loss'],label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('ViT Loss')\n",
    "\n",
    "# Accuracy history\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['ContrastiveAccuracy'],label='Training')\n",
    "plt.plot(history.history['val_ContrastiveAccuracy'],label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('ViT Accuracy')\n",
    "\n",
    "plt.tight_layout(h_pad = 5.0)\n",
    "plt.savefig('history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Loss in individual image\n",
    "plt.plot(history.history['loss'],label='Training')\n",
    "plt.plot(history.history['val_loss'],label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('ViT Loss')\n",
    "\n",
    "plt.savefig('history_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Accuracy in individual image\n",
    "plt.plot(history.history['ContrastiveAccuracy'],label='Training')\n",
    "plt.plot(history.history['val_ContrastiveAccuracy'],label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('ViT Accuracy')\n",
    "\n",
    "plt.savefig('history_acc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Realistic Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "offset = 0\n",
    "n_comp = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# update with notes to compare\n",
    "cm((x_val[0:1],x_train[offset:offset+n_comp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_val[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train[np.argmax(cm((x_val[0:1],x_train[offset:offset+n_comp])))+offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0.0\n",
    "n = 10\n",
    "with open(\"10_accuracy.txt\", 'w') as file:\n",
    "    print(\"True\\tPred\")\n",
    "    file.write(\"True\\tPred\" + '\\n')\n",
    "    for i in range(n):\n",
    "        true = y_val[i] \n",
    "        pred = y_train[np.argmax(cm((x_val[i:i+1], x_train[offset:offset+n_comp])))+offset]\n",
    "        print(true, '\\t', pred, end = '')\n",
    "        file.write(str(true) + '\\t\\t' + str(pred))\n",
    "        if (y_val[i] == y_train[np.argmax(cm((x_val[i:i+1], x_train[offset:offset+n_comp])))+offset]):\n",
    "            accuracy+= 1.0\n",
    "            print(\"\\t\\u2714\\n\")\n",
    "            file.write(\"\\t\\t\\u2714\\n\")\n",
    "        else:\n",
    "            print('\\n')\n",
    "            file.write('\\n')\n",
    "\n",
    "    accuracy /= n\n",
    "    print(f\"Accuracy: {accuracy*100}%\")\n",
    "    file.write(f\"Accuracy: {accuracy*100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = 0.0\n",
    "n = y_val.shape[0]\n",
    "print(n, \"computations to make . . .\")\n",
    "for i in range(n):\n",
    "   # print(y_val[i:i+1],end='\\t')\n",
    "    #print(y_train[np.argmax(cm((x_val[i:i+1], x_train[offset:offset+n_comp])))+offset])\n",
    "    if (i % (n / 10) == 0 or i == n - 1):\n",
    "        print(f\"\\rProgress: {i}/{n} ({(i/n)*100:.2f}%)\", end=\"\")  # Update the progress\n",
    "    if (y_val[i] == y_train[np.argmax(cm((x_val[i:i+1], x_train[offset:offset+n_comp])))+offset]):\n",
    "        accuracy+= 1.0\n",
    "\n",
    "accuracy /= n\n",
    "print(f\"\\nFinal Accuracy: {accuracy*100}%\")\n",
    "with open(\"final_accuracy.txt\", 'w') as file:\n",
    "    file.write(f\"Final Accuracy: {accuracy*100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
