{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6391f-2289-4715-b08f-a744fa7a7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdb262-93ab-40c4-885e-eff3e851e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from IPython.display import display\n",
    "import sympy as sp\n",
    "import urllib\n",
    "sp.init_printing(use_latex=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "#import os\n",
    "#os.environ['LD_LIBRARY_PATH']='/opt/conda/lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0939a81c-7469-4557-ba49-f5a33e939bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e54866-f8b1-461d-9724-eaa7a8478414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                   key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [keras.layers.Dense(ff_dim, activation=\"gelu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c1046-e88e-423e-a7f6-46c8917a52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(GPTransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                   key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [keras.layers.Dense(ff_dim, activation=\"gelu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training):\n",
    "        y = x\n",
    "        y = self.layernorm1(y, training=training)\n",
    "        y = self.att(y, y,\n",
    "                     use_causal_mask = True,\n",
    "                     training=training)\n",
    "        y = self.dropout1(y, training=training)\n",
    "        x += y\n",
    "        y = x\n",
    "        y = self.layernorm2(y, training=training)\n",
    "        y = self.ffn(y, training=training)\n",
    "        y = self.dropout2(y, training=training)\n",
    "        return x + y\n",
    "    # def call(self, inputs, training):\n",
    "    #     attn_output = self.att(inputs, inputs,\n",
    "    #                            use_causal_mask = True)\n",
    "    #     attn_output = self.dropout1(attn_output, training=training)\n",
    "    #     out1 = self.layernorm1(inputs + attn_output)\n",
    "    #     ffn_output = self.ffn(out1)\n",
    "    #     ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    #     return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5199cb3-ff33-489f-8d21-f0268d5f08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source pulled from KerasNLP: https://github.com/keras-team/keras-nlp/blob/v0.4.1/keras_nlp/layers/sine_position_encoding.py#L22\n",
    "class SinePositionEncoding(keras.layers.Layer):\n",
    "    \"\"\"Sinusoidal positional encoding layer.\n",
    "    This layer calculates the position encoding as a mix of sine and cosine\n",
    "    functions with geometrically increasing wavelengths. Defined and formulized\n",
    "    in [Attention is All You Need](https://arxiv.org/abs/1706.03762).\n",
    "    Takes as input an embedded token tensor. The input must have shape\n",
    "    [batch_size, sequence_length, feature_size]. This layer will return a\n",
    "    positional encoding the same size as the embedded token tensor, which\n",
    "    can be added directly to the embedded token tensor.\n",
    "    This layer optionally accepts `tf.RaggedTensor`s as inputs to process\n",
    "    batches of sequences of different lengths. The one ragged dimension must be\n",
    "    the dimension that corresponds to the sequence, that is, the penultimate\n",
    "    dimension.\n",
    "    Args:\n",
    "        max_wavelength: The maximum angular wavelength of the sine/cosine\n",
    "            curves, as described in Attention is All You Need. Defaults to\n",
    "            10000.\n",
    "    Examples:\n",
    "    ```python\n",
    "    # create a simple embedding layer with sinusoidal positional encoding\n",
    "    seq_len = 100\n",
    "    vocab_size = 1000\n",
    "    embedding_dim = 32\n",
    "    inputs = keras.Input((seq_len,), dtype=tf.float32)\n",
    "    embedding = keras.layers.Embedding(\n",
    "        input_dim=vocab_size, output_dim=embedding_dim\n",
    "    )(inputs)\n",
    "    positional_encoding = keras_nlp.layers.SinePositionEncoding()(embedding)\n",
    "    outputs = embedding + positional_encoding\n",
    "    ```\n",
    "    References:\n",
    "     - [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_wavelength=10000,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.max_wavelength = max_wavelength\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # TODO(jbischof): replace `hidden_size` with`hidden_dim` for consistency\n",
    "        # with other layers.\n",
    "        if isinstance(inputs, tf.RaggedTensor):\n",
    "            bounding_shape = inputs.bounding_shape()\n",
    "            position_embeddings = (\n",
    "                self._compute_trim_and_broadcast_position_embeddings(\n",
    "                    bounding_shape,\n",
    "                )\n",
    "            )\n",
    "            # then apply row lengths to recreate the same ragged shape as inputs\n",
    "            return tf.RaggedTensor.from_tensor(\n",
    "                position_embeddings,\n",
    "                inputs.nested_row_lengths(),\n",
    "            )\n",
    "        else:\n",
    "            return self._compute_trim_and_broadcast_position_embeddings(\n",
    "                tf.shape(inputs),\n",
    "            )\n",
    "\n",
    "    def _compute_trim_and_broadcast_position_embeddings(self, shape):\n",
    "        seq_length = shape[-2]\n",
    "        hidden_size = shape[-1]\n",
    "        position = tf.cast(tf.range(seq_length), self.compute_dtype)\n",
    "        min_freq = tf.cast(1 / self.max_wavelength, dtype=self.compute_dtype)\n",
    "        timescales = tf.pow(\n",
    "            min_freq,\n",
    "            tf.cast(2 * (tf.range(hidden_size) // 2), self.compute_dtype)\n",
    "            / tf.cast(hidden_size, self.compute_dtype),\n",
    "        )\n",
    "        angles = tf.expand_dims(position, 1) * tf.expand_dims(timescales, 0)\n",
    "        # even indices are sine, odd are cosine\n",
    "        cos_mask = tf.cast(tf.range(hidden_size) % 2, self.compute_dtype)\n",
    "        sin_mask = 1 - cos_mask\n",
    "        # embedding shape is [seq_length, hidden_size]\n",
    "        positional_encodings = (\n",
    "            tf.sin(angles) * sin_mask + tf.cos(angles) * cos_mask\n",
    "        )\n",
    "\n",
    "        return tf.broadcast_to(positional_encodings, shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"max_wavelength\": self.max_wavelength,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb90a2-aabd-4edb-9aeb-56b4162fe70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedTokenAndPositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, maxlen, input_dim, output_dim, **kwargs):\n",
    "        super(MaskedTokenAndPositionEmbedding, self).__init__(**kwargs)\n",
    "        self.token_emb = keras.layers.Embedding(input_dim=input_dim,\n",
    "                                                output_dim=output_dim,\n",
    "                                                mask_zero=True)\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen+1,\n",
    "                                              output_dim=output_dim,\n",
    "                                              mask_zero=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=1, limit=maxlen+1, delta=1)\n",
    "        positions = positions * tf.cast(tf.sign(x),tf.int32)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda51582-8394-4af8-a20d-46d35a11e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedTokenAndSinePositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim, max_wavelength=10000,**kwargs):\n",
    "        super(MaskedTokenAndSinePositionEmbedding, self).__init__(**kwargs)\n",
    "        self.token_emb = keras.layers.Embedding(input_dim=input_dim,\n",
    "                                                output_dim=output_dim,\n",
    "                                                mask_zero=True)\n",
    "        self.pos_emb = SinePositionEncoding(max_wavelength=max_wavelength)\n",
    "\n",
    "    def call(self, x):\n",
    "        mask = tf.expand_dims(tf.sign(x),-1)\n",
    "        x = self.token_emb(x)\n",
    "        positions = self.pos_emb(x)\n",
    "        positions = positions * mask\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f9b54-1b35-4bb8-b02f-7ed844753d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom masked loss/accuracy functions\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def MaskedSparseCategoricalCrossentropy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def MaskedSparseCategoricalAccuracy(real, pred):\n",
    "    accuracies = tf.equal(tf.cast(real,tf.int64), tf.argmax(pred, axis=2))\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b4534-9d0f-4b2a-beac-259d464608e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_filler(val):\n",
    "    if val!=\"<|endoftext|>\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def encode_seq(x,max_length=0):\n",
    "    # String to integer\n",
    "    proto_val = tokenizer(x)\n",
    "    val = tokenizer(x+(''.join([\"<|endoftext|>\"]*(max_length-len(proto_val['input_ids'])-20))))\n",
    "    input_ids = val['input_ids']\n",
    "    return input_ids\n",
    "\n",
    "def decode_seq(x):\n",
    "    test=filter(remove_filler,tokenizer.convert_ids_to_tokens(x))\n",
    "    filler_removed = list(test)\n",
    "    return tokenizer.convert_tokens_to_string(filler_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7761cae-d492-4909-aee5-9f131558717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_size = 20\n",
    "model_length = 10*segment_size\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764a18c-e0dc-4f39-9909-91f68c3b274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = len(tokenizer.get_vocab())\n",
    "embedding_size = 128\n",
    "stack = 5\n",
    "num_heads = 12\n",
    "memory_size = segment_size * 3\n",
    "\n",
    "y = x = keras.layers.Input((None,))\n",
    "y = MaskedTokenAndSinePositionEmbedding(input_dim=n_tokens,\n",
    "                                        output_dim=embedding_size)(y)\n",
    "for _ in range(stack):\n",
    "    y = GPTransformerBlock(embedding_size,\n",
    "                           num_heads,\n",
    "                           embedding_size*2)(y)\n",
    "\n",
    "y = keras.layers.Dense(n_tokens)(y)\n",
    "\n",
    "model = keras.Model(x,y)\n",
    "model.compile(loss=MaskedSparseCategoricalCrossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=MaskedSparseCategoricalAccuracy)\n",
    "model.summary()\n",
    "keras.utils.plot_model(model,show_shapes=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f42ce2-0292-4c7e-940e-70f2762d65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make file to upload to digitalocean\n",
    "#tar -xcvf training_1.tar.gz training_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6464f4-7d7a-426f-9bd6-2c135fd317f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and extract file from digitalocean\n",
    "#curl -O https://s-stem-data.nyc3.digitaloceanspaces.com/P_D_Weights/training_1.tar.gz\n",
    "#tar -xzvf training_1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50e14f-e8cc-413d-97bc-2c565ab45a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('curl -O https://s-stem-data.nyc3.digitaloceanspaces.com/Austen.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b920f-9fd8-406e-b584-1801275a21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('curl -O https://s-stem-data.nyc3.digitaloceanspaces.com/P_D_Weights/training_1.tar.gz')\n",
    "os.system('tar -xzvf training_1.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5535b-8e83-4f37-8a6e-c5f5ceb86d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996af1fc-5b02-4e16-93b5-e75de4fc9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351bc23-2485-49ab-b9e5-4c0864bb555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, max_length, batch_size=32, **kwargs):\n",
    "        super(DataGenerator, self).__init__(**kwargs)\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data # a handle only...\n",
    "        self.indices = np.arange(self.data[0].shape[0])\n",
    "        self.max_length = max_length\n",
    "        self.idx = 0\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'The number of batches per epoch'\n",
    "        return int(np.floor(self.data[0].shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one (enumerated) batch of data'\n",
    "        # Generate indices for a batch and grab batch\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        return self.__data_generation(indices)\n",
    "\n",
    "    def __data_generation(self, ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Generate data\n",
    "        x = tf.convert_to_tensor(self.data[0][ids],dtype=tf.int32)\n",
    "        y = tf.convert_to_tensor(self.data[1][ids],dtype=tf.int32)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        return np.random.shuffle(self.indices)\n",
    "\n",
    "    ## Needed for TF Dataset conversion...\n",
    "    def output_signature(self):\n",
    "        sig = self[0]\n",
    "        return (tf.TensorSpec.from_tensor(sig[0]),\n",
    "                tf.TensorSpec.from_tensor(sig[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9877d9c-2b54-47fa-af9d-5a494698354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Austen.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "text = []\n",
    "j = 0\n",
    "for i in range(len(lines)-1):\n",
    "    if lines[i] == '':\n",
    "        line = ' '.join(lines[j:i])\n",
    "        if line != '':\n",
    "            text = text + [line[k:k+model_length-2] for k in range(0, len(line), model_length-2)]\n",
    "            # text = text + [line]\n",
    "        j = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be09cce-1b13-4b12-9a85-ee1d04579287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset? - All of the data will take some time...\n",
    "n_seq = len(text)\n",
    "n_seq = 1000\n",
    "split_point = int(n_seq * 0.8)\n",
    "text = text[:n_seq]\n",
    "np.random.shuffle(text) # In-place modification\n",
    "max_length = np.max([len(i) for i in text])+2 # Start+stop\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c9063-fb02-4e0e-a611-68c166765028",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([encode_seq(x,max_length + (segment_size - (max_length-1) % segment_size)) for x in text])\n",
    "training = DataGenerator((X[:split_point,:-1],\n",
    "                          X[:split_point,1:]),model_length,batch_size)\n",
    "validation = DataGenerator((X[split_point:,:-1],\n",
    "                            X[split_point:,1:]),model_length,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8c4b8-c04c-4fd0-9936-44842640ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy:',model.evaluate(training)[1]*100.0,'%')\n",
    "print('Validation Accuracy:',model.evaluate(validation)[1]*100.0,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e1928-6365-442a-a799-998ea52b53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_token(x):\n",
    "    x = np.cumsum(x)\n",
    "    return np.argmax(x > np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e40f53-39e2-4630-888c-3769818af414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off teacher forcing...\n",
    "# Prompt (needs to be at least 1 - the start token?...)\n",
    "i = 5\n",
    "data = training[0][0][i:i+1]\n",
    "prompt = 3\n",
    "tokens = np.full(data.shape,dtype=np.int32,fill_value=50256)\n",
    "tokens[0,0:prompt] = data[:,0:prompt]\n",
    "\n",
    "print(\"Original:\")\n",
    "print(decode_seq(data[0]))\n",
    "print()\n",
    "\n",
    "print(\"Prompt:\")\n",
    "print(decode_seq(tokens[0]))\n",
    "print()\n",
    "\n",
    "print(\"Decoding:\")\n",
    "print(decode_seq(tokens[0]),end='')\n",
    "for x in range(prompt,data.shape[1]-1):\n",
    "    probabilities = keras.activations.softmax(model(tokens)).numpy()[0,x-1]\n",
    "    # Most likely token...\n",
    "    result = probabilities.argmax(-1)\n",
    "    # Sampled token...\n",
    "    result = np.apply_along_axis(select_token, -1, probabilities)\n",
    "    tokens[0,x] = result\n",
    "    if result == 50256:\n",
    "        break # Stop token found!\n",
    "    print(decode_seq(tokens[0,x:x+1]),end='')\n",
    "print()\n",
    "print()\n",
    "\n",
    "result = model(tokens).numpy()\n",
    "print(\"Remodeled:\")\n",
    "print(decode_seq(result.argmax(-1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790793c6-1b95-4734-a1fa-e9d7a89da1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
